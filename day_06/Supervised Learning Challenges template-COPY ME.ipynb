{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Challenges\n",
    "\n",
    "\n",
    "Get the [congressional votes data](house-votes-84.csv) in your repo.\n",
    "\n",
    "These are votes of U.S. House of Representatives Congressmen on 16 key\n",
    "issues in 1984. You can find more information about it [here](house-votes-84-description.txt).\n",
    "\n",
    "We will try to see if we can predict the house members' party based on\n",
    "their votes.   \n",
    "We will also use some of the general machine learning tools we learned.\n",
    "\n",
    "#### Challenge 1 `[Python]`\n",
    "Load the data into a pandas dataframe. Replace `'y'`s with `1`s, `'n'`s with\n",
    "`0`s.\n",
    "\n",
    "Now, almost every representative has a `?`. This represents a no vote\n",
    "(they were absent or some other similar reason). If we dropped all the\n",
    "rows that had a `?`, we would throw out most of our data. Instead, we\n",
    "will replace `?` with the _best guess_ (in the Bayesian sense): in the\n",
    "absence of any other information, we will say that the probability of\n",
    "the representative saying YES is the ratio of others that said YES\n",
    "over the whole votes.\n",
    "\n",
    "So, convert each `?` to this probability (when yes=1 and no=0, this is\n",
    "the mean of the column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2 `[Modeling]`\n",
    "Split the data into a test and training set. Use this\n",
    "function:\n",
    "\n",
    "    from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3 `[Modeling]`\n",
    "Using scikit.learn's KNN algorithm, train a model that predicts the\n",
    "party (republican/democrat):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Read the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). \n",
    "Get your X (columns of features) and Y (target column) vectors ready for fitting and evaluating. \n",
    "Initiate the model with `knn_model = KNeighborsClassifier(n_neighbors=1)` (for a k=1 KNN). \n",
    "Call `.fit(X, Y)` on the `knn_model` with the X and Y from the training set.\n",
    "\n",
    "Try it with a lot of different k values (number of neighbors), from 1\n",
    "to 20, and on the test set calculate the accuracy (number of correct\n",
    "predictions / number of all predictions) for each k\n",
    "\n",
    "You can use this to calculate accuracy:\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "Which k value gives the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 4 `[Modeling]`\n",
    "Make a similar model but with scikit.learn's `LogisticRegression` instead. Calculate\n",
    "test accuracy. Google the documentation. The fit / predict interface is the same for all models in scikit.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 5 `[Python]`\n",
    "Make a bar graph of democrats and republicans. How many of each are\n",
    "there?\n",
    "\n",
    "Make a very simple predictor that predicts 'democrat' for every\n",
    "incoming example.   \n",
    "(Just make a function that takes in an `X`  --an array or matrix with\n",
    "input examples--, and returns an array of the same length as `X`, where\n",
    "each value is 'democrat'. For example, if `X` is three rows, your\n",
    "function should return `['democrat','democrat','democrat']`) Make a\n",
    "`y_predicted` vector using this and measure its accuracy.\n",
    "\n",
    "Do the same with predicting 'republican' all the time and measure its\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 6 `[Visualization]`\n",
    "Plot the accuracies of each predictor as a function of k. Since k only matters for KNN,\n",
    "your logistic regression accuracy, 'democrat' predictor accuracy and\n",
    "'republican' predictor accuracy will stay the same over all k, so each\n",
    "of these three will be a horizontal line. But the KNN accuracy will\n",
    "change with k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 7 `[Modeling]`\n",
    "When you found the k value with highest test accuracy in Challenge 3, you used a single test set. \n",
    "Use scikit.learn's cross-validation tools to get a range of accuracies for each k. \n",
    "Using the average cross validation accuracy, does the best k change? \n",
    "Can you imagine cases where it might and might not change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 8 `[Visualization]`\n",
    "Like in Challenge 6, make a graph of  accuracies for each k value. \n",
    "This time, put error bars in your graph, using your results from Challenge 7.\n",
    "Use the standard deviation of the cross validation accuracy values for each k as its error bar height (for the KNN predictor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 9 `[Modeling]`\n",
    "Calculate the accuracy, precision, recall and f1 scores on the test set for each classifier you built (including the trivial ones).\n",
    "(Use only one KNN with the best k, no need to do this for all k values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 10 `[Modeling]`\n",
    "Calculate the same metrics as in Challenge 9, but use cross validation instead of that test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 11a `[Python]`\n",
    "A Portuguese bank is having a telemrketing campaign. They try to get their clients to subscribe to a term deposit product. Often more than one call to the same client is required. They have been recording their success or failure with each client, along with all the data they have on that client. To cut costs, the bank wants to predict who is likely to subscribe, so they can call those clients and not waste time and money calling people that likely won't subscribe anyway. To that end, [here are their records so far](https://github.com/thisismetis/capitalone-pilottwo/blob/master/project_2/data/bank/bank.csv). You can learn more about each column [here](https://github.com/thisismetis/capitalone-pilottwo/blob/master/project_2/data/bank/bank-description.md).\n",
    "\n",
    "Build a  classifier with all the numeric features. Calculate the accuracy, precision, and recall for identifying the subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 11b `[Modeling]`\n",
    "Is this a good predictor? Which features are contributing the most? Check if any single feature that you included in your model might be driving the classifier. If so, why? Can you use this model successfully? Can you use a model with just that column? Is something wrong? (Hint: You should not use one of the columns, but it is not obvious at initial look. Find out which one and why that might be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The rest is completely optional specialization challenges. Select the ones you're excited about, or explore other things you got curious about through the first 11-ish challenges._\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "\n",
    "#### Extra `[Python]` & `[Modeling]` Challenge A\n",
    "\n",
    "Instead of 'democrat' or 'republican', can you predict the vote of a\n",
    "representative based on their other votes?\n",
    "\n",
    "Reload the data from scratch. Convert y-->1, n-->0.\n",
    "\n",
    "Choose one vote. Build a classifier (logistic regression or KNN), that\n",
    "uses the other votes (do not use the party as a feature) to predict if\n",
    "the vote will be 1 or 0.\n",
    "\n",
    "Convert each ? to the mode of the column (if a senator has not voted,\n",
    "make their vote 1 if most others voted 1, make it 0 if most others\n",
    "voted 0).\n",
    "\n",
    "Calculate the cross validation accuracy of your classifier for\n",
    "predicting how each representative will vote on the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra `[Modeling]` Challenge B\n",
    "\n",
    "Back to your movie data! Choose one categoric feature to predict. \n",
    "We mention MPAA Rating in the slides, but genre, month, etc. are all decent choices. If\n",
    "you don't have any non-numeric features, you can make two bins out of\n",
    "a numeric one (like \"Runtime>100 mins\" and \"Runtime<=100 mins\")\n",
    "\n",
    "Make a bar graph of how many of each movie there is in the data. For\n",
    "example, with Ratings, show how many G, PG, PG-13, R movies there are,\n",
    "etc. (basically a histogram of your labels).\n",
    "\n",
    "Predict your outcome variable (target/labels) using KNN and logistic\n",
    "regression. Calculate their accuracies.\n",
    "\n",
    "Make a baseline stupid predictor that always predicts the label that\n",
    "is present the most in the data. Calculate its accuracy on a test set.\n",
    "\n",
    "How much better do KNN and logistic regression do versus the baseline?\n",
    "\n",
    "What are the coefficients of logistic regression? Which features\n",
    "affect the outcome how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra`[Modeling]` Challenge C\n",
    "\n",
    "This is a preview of many other classification algorithms. Scikit.learn has the same interface for all of these, so you\n",
    "can use them exactly the same way as you did `LogisticRegression` and\n",
    "`KNeighborsClassifier`. Use each of these to classify your data and\n",
    "print the test accuracy of each:\n",
    "\n",
    "Gaussian Naive Bayes\n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "SVM (Support Vector Machine) Classifier\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "Random Forest\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra `[Python]` Challenge D\n",
    "\n",
    "The representative votes dataset\n",
    "only had 0s and 1s. Let's just swiftly tackle the breast cancer\n",
    "surgery data we talked about in class.\n",
    "\n",
    "The data is [in the repository](haberman.csv). You can learn more about it [here](https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival).\n",
    "\n",
    "- What is the average and standard deviation of the age of all of the\n",
    "patients?\n",
    "- What is the average and standard deviation of the age of those\n",
    "patients that survived 5 or more years after surgery?\n",
    "- What is the average and standard deviation of the age of those\n",
    "patients who survived fewer than 5 years after surgery?\n",
    "- Plot a histogram of the ages side by side with a histogram of the\n",
    "number of axillary nodes.\n",
    "- What is the earliest year of surgery in this dataset?\n",
    "- What is the most recent year of surgery?\n",
    "- Use logistic regression to predict survival after 5 years. How well\n",
    "does your model do?\n",
    "- What are the coefficients of logistic regression? Which features\n",
    "affect the outcome how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra `[Modeling]` & `[Visualization]` Challenge E\n",
    "For each representatives classifier (KNN and logistic regression), draw the ROC curve and calculate the AUC.\n",
    "As a `[Visualitation]` track bonus, make the ROC curve look good, following good data visualization principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
